---
title: Data Wrangler
jupyter: python3
---


```{python}
#| ExecuteTime: {end_time: '2025-10-09T16:32:15.477079Z', start_time: '2025-10-09T16:32:14.953166Z'}
import pandas as pd
import numpy as np
from lxml import etree # lxml, da grosse dateien bei apple
import glob
from pathlib import Path
from datetime import datetime
import warnings

warnings.filterwarnings("ignore")
```

## LE1: Importieren

**[INTERNAL COMMENT – REMOVE BEFORE FINAL]**

**KERNPROBLEME:**

- Die Eigenheit unseres Wranglings erfordert andere Reihenfolge der Operationen, weil:
    1. Import der gesamten Apple-Rohdaten technisch nicht valabel ist und darum eine Vorauswahl gemacht werden muss.
  2. Ein Filter nach Sportart (eigentlich LE3) vor LE2 gemacht werden muss, weil sonst LE2 nicht sinnvoll ausgeführt werden kann und LE3 sinngemäss für jede zu analysierende Sportart separat erneut gemacht werden müsste.

        - Der Grund dafür liegt einerseits in der unterschiedlichen Natur der einzelnen Sportarten, die an das Bereinigen (LE2) und Transformieren (LE3) jeweils unterschiedliche Anforderungen stellen. Bsp: Pace, HF-Zonen, Distanz, Dauer sind bei Running vergleichbar – bei Rad/Schwimmen wären Skalen und Verteilungen völlig anders. Entsprechend müssen z.B. Imputationen (LE2) anders berechnet werden.

        - Anderseits sind die Apple Daten nicht /tidy/: Ein Frame entspricht nicht einem Kernthema/Frage, sondern erfüllt andere Funktionen.

**VORSCHLÄGE:**

- Idee: Ganzes DAW Projekt auf Lauftrainings ausrichten (+ Project Goal im Pitch entsprechend anpassen)

- Bei Garmin ist das einfach mit activity_type==running als Filter zwischen Importfunktion in LE1 und Beginn von LE2

- Bei Apple ist das komplizierter. Wir haben 2 Möglichkeiten:

        1. Im XML-Parsing selber filtern: spart minimal RAM, macht aber code weniger schlank und vermischt import (LE1) und filter (LE3)
        2. Nach dem XML-Parsing: Ablauf klarer durch Auslagerung aus der Funktion import_apple_workouts, aber vor beginn von LE2, also noch im codechunk zu LE1




**MEINE ÄNDERUNGEN:**

    - habe im APPLE-Chunk alle Zeilen die keine Abdeckung mit Garmin- Variabeln haben #inaktiviert.
    - habe im Garmin Code nach Importfunktion nach activity_type==running gefiltert, ist einfach wieder löschbar.
    - Vorschlag änderung für Pitch: "Wir fokussieren auf Lauftrainings, um LE2/LE3 valide, konsistent und reproduzierbar umzusetzen. Imputation, Ausreisserregeln und Aggregationen sind sportartspezifisch. Dieser Fokus erlaubt saubere Methoden und eine robuste Pipeline."


### 1.1 Garmin Data Import Strategy

Datenquelle: CSV-Export aus Garmin Connect mit strukturierten Aktivitätsdaten.

Besondere Herausforderungen:
  - Encoding-Problem: CSV-Dateien verwenden latin-1 statt Standard utf-8
  - Semi-kolon Separator (europäisches Format)
  - Spaltennamen nicht standardisiert (Leerzeichen, deutsche Umlaute möglich)

Lösung: Multi-Encoding-Parser mit automatischer Erkennung und Spalten-Standardisierung.

```{python}
#| ExecuteTime: {end_time: '2025-10-09T16:32:15.490284Z', start_time: '2025-10-09T16:32:15.482995Z'}
def import_garmin_activities(data_path="data/garmin/*/Activities.csv"):
    """
    Import all Garmin CSV files and combine into single DataFrame
    Handle encoding issues (Garmin exports often use Latin-1/ISO-8859-1)
    """
    garmin_files = glob.glob(data_path)
    garmin_dfs = []

    for file in garmin_files:
        # Extract date from path (e.g., 2025-08-22)
        export_date = Path(file).parent.name

        # Try different encodings commonly used by Garmin
        encodings = ["latin-1", "iso-8859-1", "utf-8", "cp1252"]
        df = None

        for encoding in encodings:
            try:
                df = pd.read_csv(file, sep=";", encoding=encoding)
                print(f"Successfully read {file} with encoding: {encoding}")
                break
            except UnicodeDecodeError:
                continue

        if df is None:
            print(f"Failed to read {file} with any encoding")
            continue

        df["source"] = "garmin" #harmonisierung mit apple
        df["export_date"] = export_date

        # Standardize column names for later joining (noch Teil von LE1: Struktur angleichen, nicht Daten bereinigen)
        # Ziel: Einheitliche Tabellenstruktur für spätere Verarbeitung in LE2–LE4
        df = df.rename(
            columns={
                "Activity Type": "activity_type",
                "Date": "date",
                "Distance": "distance_km",
                "Calories": "calories",
                "Time": "duration",
                "Avg HR": "avg_heart_rate",
                "Max HR": "max_heart_rate",
            }
        )

        garmin_dfs.append(df)

    return pd.concat(garmin_dfs, ignore_index=True) if garmin_dfs else pd.DataFrame()
```

```{python}
#| ExecuteTime: {end_time: '2025-10-09T16:32:16.013925Z', start_time: '2025-10-09T16:32:15.984471Z'}
# Test the function
garmin_df = import_garmin_activities()
print(f"Garmin activities imported: {len(garmin_df)}")
print(f"Activity types: {garmin_df['activity_type'].unique()}")
garmin_df.head(3)
```

### 1.2 Apple Health Data Import Strategy

**Datenquelle**: XML-Export aus Apple Health App mit verschachtelter Struktur.

**Besondere Herausforderungen**:
  - Sehr große XML-Dateien (mehrere MB) → Memory-effizientes Parsing erforderlich
  - Verschachtelte Datenstruktur: `<Workout>` -> `<WorkoutStatistics>` + `<MetadataEntry>`
  - Fehlende direkte Attribute: Distance/Calories stehen in separaten Child-Elementen
  - Viele verschiedene Metriken je nach Workout-Typ, aber nur wenige für spätere Analysen nötig



**Lösung**:
Streaming XML-Parser mit gezielter Extraktion der relevanten Kernvariablen aus zwei XML-Bereichen:
  - **Workout-Attribute**: `activity_type`, `date`, `duration`, `source`, `export_date`
  - **WorkoutStatistics**: `distance_km`, `calories`, `avg_heart_rate`, `max_heart_rate`

Damit wird der Import ressourcenschonend, das Schema bleibt schlank, und die Daten sind von Beginn an mit Garmin harmonisiert.


**Zusätzliche Datenquellen identifiziert**:
  - GPX-Dateien in workout-routes/: GPS-Punkte pro Workout mit Speed, Course, Elevation für detaillierte räumliche Analysen

**Import-Strategie erfolgreich**: Separate DataFrames ermöglichen individuelle Bereinigung (LE2) und flexible Join-Strategien (LE4).

```{python}
#| ExecuteTime: {end_time: '2025-10-09T16:32:16.095728Z', start_time: '2025-10-09T16:32:16.089244Z'}
def import_apple_workouts(xml_path="data/apple/*/Export.xml"):
    """
    Import Apple Health workouts keeping only Garmin-compatible core variables.
    All Apple-specific extras are commented out for easy reactivation.
    """
    xml_files = glob.glob(xml_path)
    apple_workouts = []

    for xml_file in xml_files:
        export_date = Path(xml_file).parent.name
        print(f"Processing Apple Health file: {xml_file}")

        for event, elem in etree.iterparse(xml_file, events=("start", "end")):
            if event == "end" and elem.tag == "Workout":
                # --- Workout-Attribute ---
                workout_data = {
                    # Basic info (keep)
                    "source": "apple",
                    "export_date": export_date,
                    "activity_type": elem.get("workoutActivityType", "").replace("HKWorkoutActivityType", ""),
                    "date": elem.get("startDate", ""),

                    # Duration (keep; convert to seconds in LE2)
                    "duration": elem.get("duration", ""),

                    # --- commented out (not in Garmin schema) ---
                    # "end_date": elem.get("endDate", ""),
                    # "creation_date": elem.get("creationDate", ""),
                    # "duration_unit": elem.get("durationUnit", ""),
                    # "source_name": elem.get("sourceName", ""),
                    # "source_version": elem.get("sourceVersion", ""),
                    # "device": elem.get("device", ""),

                    # Initialize Garmin-core measurements
                    "distance_km": "",
                    "calories": "",          # will be set from ActiveEnergyBurned
                    "avg_heart_rate": "",
                    "max_heart_rate": "",

                    # --- commented out Apple-only metrics ---
                    # "min_heart_rate": "",
                    # "steps": "",
                    # "running_stride_length": "",
                    # "running_vertical_oscillation": "",
                    # "running_ground_contact_time": "",
                    # "running_power": "",
                    # "running_speed": "",
                    # "indoor_workout": "",
                    # "average_mets": "",
                    # "weather_temperature": "",
                    # "weather_humidity": "",
                    # "timezone": "",
                    # "elevation_ascended": "",
                }

                # --- WorkoutStatistics ---
                for stats_elem in elem.findall("WorkoutStatistics"):
                    stats_type = stats_elem.get("type", "")

                    # Distance (keep)
                    if stats_type in (
                        "HKQuantityTypeIdentifierDistanceWalkingRunning",
                        "HKQuantityTypeIdentifierDistanceCycling",
                    ):
                        workout_data["distance_km"] = stats_elem.get("sum", "")

                    # Calories (keep) -> set directly from ActiveEnergyBurned (Garmin-style)
                    elif stats_type == "HKQuantityTypeIdentifierActiveEnergyBurned":
                        workout_data["calories"] = stats_elem.get("sum", "")

                    # Heart Rate (keep: avg/max)
                    elif stats_type == "HKQuantityTypeIdentifierHeartRate":
                        workout_data["avg_heart_rate"] = stats_elem.get("average", "")
                        workout_data["max_heart_rate"] = stats_elem.get("maximum", "")

                    # --- commented out (Apple-only) ---
                    # elif stats_type == "HKQuantityTypeIdentifierBasalEnergyBurned":
                    #     pass  # we don't keep basal in LE1
                    # elif stats_type == "HKQuantityTypeIdentifierStepCount":
                    #     pass
                    # elif stats_type == "HKQuantityTypeIdentifierRunningStrideLength":
                    #     pass
                    # elif stats_type == "HKQuantityTypeIdentifierRunningVerticalOscillation":
                    #     pass
                    # elif stats_type == "HKQuantityTypeIdentifierRunningGroundContactTime":
                    #     pass
                    # elif stats_type == "HKQuantityTypeIdentifierRunningPower":
                    #     pass
                    # elif stats_type == "HKQuantityTypeIdentifierRunningSpeed":
                    #     pass

                # --- MetadataEntry (all commented out in LE1) ---
                # for metadata_elem in elem.findall("MetadataEntry"):
                #     key = metadata_elem.get("key", "")
                #     value = metadata_elem.get("value", "")
                #     # Not needed for Garmin schema in LE1

                apple_workouts.append(workout_data)
                elem.clear()

    return pd.DataFrame(apple_workouts) if apple_workouts else pd.DataFrame()
```

```{python}
#| ExecuteTime: {end_time: '2025-10-09T16:32:27.933820Z', start_time: '2025-10-09T16:32:16.171465Z'}
# Test the function
apple_df = import_apple_workouts()
print(f"Apple workouts imported: {len(apple_df)}")
print(f"Activity types: {apple_df['activity_type'].unique()}")

apple_df.head(3)

```

## LE2: Bereinigen


**Ziel**:
- Rohdaten beider Quellen so bereinigen, dass sie für statistische Auswertung geeignet sind.
- Da Garmin- und Apple-Daten unterschiedliche Strukturen und Umfang haben, erfolgt die Bereinigung **pro Quelle**, aber auf einem **gemeinsamen harmonisierten Schema**.

**Vorgehen**:

1. **Bereinigung pro Quelle (Garmin / Apple)**
   - **Fehlerhafte oder unplausible Werte** erkennen und behandeln (z. B. negative Distanzen, unrealistische Herzfrequenzen).
   - **Duplikate** entfernen.
   - **Fehlende Werte** je Variable nach festen Regeln imputieren oder droppen (z. B. keine Imputation bei Distanz oder Dauer).
   - **Ausreisser** mithilfe der IQR-Methode identifizieren und wahlweise entfernen oder winsorisieren.
   - **Kategorische Variablen** vereinheitlichen (z. B. „Run“ → „Running“).

2. **Qualitätsprüfung & Reflexion**
   - Vergleich der deskriptiven Statistiken **vor und nach** der Bereinigung.
   - Dokumentation, wie sich Bereinigungsschritte auf Mittelwerte, Varianzen und Korrelationen auswirken.
   - Separate Reports pro Quelle, um Nachvollziehbarkeit und Reproduzierbarkeit sicherzustellen.

**Ergebnis**:
Zwei saubere, konsistent strukturierte DataFrames (`garmin_clean`, `apple_clean`).

### 2.1 Garmin Data Cleaning


**Ziel**:
Die Garmin-Daten werden bereinigt, um fehlerhafte, doppelte oder unplausible Einträge zu entfernen und fehlende Werte gezielt zu behandeln.
Da Garmin-Exports tendenziell strukturierter, aber nicht immer vollständig sind (z. B. fehlende Herzfrequenzen, abgebrochene Aktivitäten), erfolgt die Bereinigung regelbasiert und reproduzierbar.

**Vorgehen**:

1. **Filter nach Laufsport**

1. **Typisierung und Einheiten**
   - `date` → in `datetime` umwandeln (`%Y-%m-%d %H:%M:%S`).
   - `distance_km` → sicherstellen, dass Einheit Kilometer ist (ggf. Meter → km konvertieren).
   - `duration` → von `"hh:mm:ss"` in Sekunden (`duration_sec`) konvertieren.
   - Alle numerischen Spalten (`distance_km`, `duration_sec`, `calories`, `avg_heart_rate`, `max_heart_rate`) in `float` casten.

2. **Duplikate**
   - Doppelte Aktivitäten identifizieren über `["date", "distance_km", "duration_sec"]`.
   - Exakte Duplikate entfernen.
   - Bei fast-identischen Läufen (z. B. Doppelexport) nur den ersten Eintrag behalten.

3. **Fehlende Werte**
   - **`date`, `distance_km`, `duration_sec`**: Zeilen droppen, wenn fehlend.
   - **`avg_heart_rate`, `max_heart_rate`, `calories`**:
     - Fehlende Werte pro Quelle (`source="garmin"`) mit Median imputieren.
     - Dokumentieren, wie viele Werte ersetzt wurden.

4. **Ausreisser**
   - Plausibilitätsgrenzen:
     - `distance_km` ∈ [0.1 ; 50]
     - `duration_sec` ∈ [120 ; 14400] (= 2 min – 4 h)
     - `avg_heart_rate` ∈ [80 ; 210]
   - Werte ausserhalb dieser Bereiche entfernen.
   - Zusätzlich IQR-Methode für `distance_km` zur Erkennung extremer Abweichungen.

5. **Konsistenzchecks**
   - Wenn `avg_heart_rate` > `max_heart_rate` → Werte tauschen oder Null setzen.
   - `pace_min_per_km` berechnen und prüfen, ob 2 ≤ Pace ≤ 7 min/km (sonst markieren).

6. **Ergebnis**
   - Bereinigter DataFrame `garmin_clean` mit konsistenten Typen, plausiblen Werten und ohne Duplikate.
   - Deskriptive Statistik vor/nach Bereinigung dokumentieren (`df.describe()`-Vergleich).
   - Optional: Histogramme und Scatterplots (Distanz, Dauer, Herzfrequenz) zur visuellen Prüfung.

### Filter nach Laufsport

**Ziel**:
Nur Laufaktivitäten (`activity_type == "Running"`) für die Analyse behalten, um Vergleichbarkeit sicherzustellen.

**Vorgehen**:
Nach dem Import werden alle Aktivitäten gefiltert, sodass nur Zeilen mit `Running` erhalten bleiben.

**Ergebnis**:
Datensatz enthält ausschliesslich Lauftrainings und bildet die Grundlage für alle weiteren Bereinigungs- und Transformationsschritte.

```{python}
#| ExecuteTime: {end_time: '2025-10-09T16:32:27.999073Z', start_time: '2025-10-09T16:32:27.986686Z'}
# Analysefokus definieren (Laufsport)

garmin_df = import_garmin_activities()

if "activity_type" in garmin_df.columns:
    before = len(garmin_df)
    garmin_df = garmin_df[garmin_df["activity_type"].str.lower().str.contains("run", na=False)].copy()
    after = len(garmin_df)
    print(f"Scope-Filter: kept {after}/{before} rows where activity_type == 'Running'")
```

### Reduktion auf Kern Aktivitäten

```{python}
#| ExecuteTime: {end_time: '2025-10-09T16:32:28.058759Z', start_time: '2025-10-09T16:32:28.051944Z'}
# Gemeinsames Schema mit Apple (LE1-Ergebnis)
core_cols = [
    "date", "activity_type", "distance_km", "duration",
    "calories", "avg_heart_rate", "max_heart_rate",
    "source", "export_date"
]

# 1) Auf vorhandene Kernspalten reduzieren
present = [c for c in core_cols if c in garmin_df.columns]
missing = [c for c in core_cols if c not in garmin_df.columns]

garmin_df_core = garmin_df[present].copy()

# 2) Fehlende Kernspalten als leere Spalten anlegen (kompatibel zu Apple)
for c in missing:
    garmin_df_core[c] = pd.NA

# 3) Spalten in Zielreihenfolge anordnen
garmin_df_core = garmin_df_core[core_cols]


```

### Typisierung und Einheiten (Garmin)

**Ziel**:
In diesem Schritt werden die Rohdaten aus den Garmin-CSV-Dateien in eine einheitlich auswertbare Form gebracht.
Dabei geht es **nicht** um die Bereinigung fehlerhafter Werte, sondern um die **Vorbereitung der Datentypen und Einheiten**, damit anschliessende Analysen oder statistische Verfahren korrekt rechnen können.


**Vorgehen**:
1. `date` wird in das Datumsformat (`datetime64`) konvertiert.
   → ermöglicht Zeitreihen-Analysen und Datumsoperationen.
2. `duration` wird aus Textformat (`hh:mm:ss` oder `mm:ss`) in Sekunden (`duration_sec`) umgerechnet.
   → erleichtert Berechnungen von Pace, Geschwindigkeit und Dauervergleichen.
3. `distance_km` wird geprüft – falls Werte über 200 vorkommen, wird angenommen, dass sie in **Metern** vorliegen, und durch 1000 geteilt.
4. Alle numerischen Variablen (`distance_km`, `duration_sec`, `calories`, `avg_heart_rate`, `max_heart_rate`) werden zu `float`.
   → sichert mathematische Operationen und Imputationsverfahren in LE2.
5. Kategorische Variablen (`activity_type`, `source`) werden als `category` typisiert.
   → spart Speicherplatz und ermöglicht Gruppenanalysen.
6. Abschliessend wird eine Übersicht der wichtigsten numerischen Spalten ausgegeben (`describe()`).

**Ergebnis**:
Ein DataFrame `garmin_df_typed` mit konsistenten Datentypen, normierten Einheiten und neuen Variablen (`duration_sec`),
der als Grundlage für die weitere Datenbereinigung dient.

```{python}
#| ExecuteTime: {end_time: '2025-10-09T16:32:28.151547Z', start_time: '2025-10-09T16:32:28.125738Z'}

def convert_duration_to_seconds(duration_str):
    """
    Converts Garmin duration strings ('hh:mm:ss' or 'mm:ss') into total seconds.
    Handles missing or malformed entries gracefully (returns NaN).
    """
    if pd.isna(duration_str):
        return np.nan
    try:
        parts = [float(x) for x in str(duration_str).split(":")]
        if len(parts) == 3:  # hh:mm:ss
            return parts[0] * 3600 + parts[1] * 60 + parts[2]
        elif len(parts) == 2:  # mm:ss
            return parts[0] * 60 + parts[1]
        else:
            return float(duration_str)  # already numeric
    except Exception:
        return np.nan


def clean_garmin_typing(df):
    """
    Converts datatypes and normalizes key units for Garmin data.
    Designed for harmonized schema (core_cols only).
    """
    df = df.copy()

    # 1️ Datum in datetime-Format konvertieren
    df["date"] = pd.to_datetime(df["date"], errors="coerce")

    # 2️ Dauer (hh:mm:ss → Sekunden)
    df["duration_sec"] = df["duration"].apply(convert_duration_to_seconds)

    # 3️ Distanz prüfen und ggf. Meter → Kilometer konvertieren
    if df["distance_km"].dropna().max() > 200:
        df["distance_km"] = df["distance_km"] / 1000

    # 4️ Numerische Typisierung
    numeric_cols = ["distance_km", "duration_sec", "calories", "avg_heart_rate", "max_heart_rate"]
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors="coerce")

    # 5️ Kategorische Typisierung
    df["activity_type"] = df["activity_type"].astype("category")
    df["source"] = df["source"].astype("category")

    # 6️ Überblick der wichtigsten numerischen Variablen
    print("\n✅ Garmin: Typisierung & Einheiten abgeschlossen.")
    print(df[numeric_cols].describe().T.round(2))

    return df


# Typisierung & Einheiten auf Garmin-Daten anwenden
garmin_df_typed = clean_garmin_typing(garmin_df_core)
```

### 2.2 Apple Data Cleaning




## LE3: Transformieren




## LE4: Verknüpfen




## LE5: Datenpipelines




## LE6: Reproduzierbarkeit

